//! # Crash Recovery: System Failure Tests
//!
//! How does the system behave during and after catastrophic failures?
//!
//! ## Attack Scenarios:
//! 1. Mid-operation failures
//! 2. Corruption handling
//! 3. Graceful degradation
//! 4. Recovery from partial state

use qc_01_peer_discovery::{
    IpAddr, KademliaConfig, NodeId, PeerInfo, RoutingTable, SocketAddr, Timestamp,
};
use qc_06_mempool::domain::{
    entities::{MempoolConfig, MempoolTransaction, SignedTransaction, U256},
    pool::TransactionPool,
};

use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::Arc;
use std::time::Duration;
use tokio::sync::Mutex;

#[derive(Clone)]
struct MockMempoolGateway;

#[async_trait::async_trait]
impl qc_10_signature_verification::ports::outbound::MempoolGateway for MockMempoolGateway {
    async fn submit_verified_transaction(
        &self,
        _tx: qc_10_signature_verification::domain::entities::VerifiedTransaction,
    ) -> Result<(), qc_10_signature_verification::ports::outbound::MempoolError> {
        Ok(())
    }
}

fn create_tx(sender_byte: u8, nonce: u64, gas_price: u64) -> MempoolTransaction {
    let signed_tx = SignedTransaction {
        from: [sender_byte; 20],
        to: Some([0xBB; 20]),
        value: U256::zero(),
        nonce,
        gas_price: U256::from(gas_price),
        gas_limit: 21000,
        data: vec![],
        signature: [0u8; 64],
    };
    MempoolTransaction::new(signed_tx, 1000)
}

// ============================================================================
// MID-OPERATION FAILURE TESTS
// ============================================================================

/// BRUTAL TEST: Power failure during block proposal
///
/// Simulates system crash mid-proposal
#[tokio::test]
async fn brutal_mid_proposal_failure() {
    let mut pool = TransactionPool::new(MempoolConfig {
        max_transactions: 100,
        pending_inclusion_timeout_ms: 100,
        ..MempoolConfig::default()
    });

    // Fill pool
    let mut hashes = Vec::new();
    for i in 0..50u8 {
        let tx = create_tx(i, 0, 1_000_000_000);
        hashes.push(tx.hash);
        pool.add(tx).unwrap();
    }

    // Start proposal (simulates leader proposing)
    pool.propose(&hashes[..25], 1, 0);

    assert_eq!(pool.pending_inclusion_count(), 25);
    assert_eq!(pool.pending_count(), 25);

    // CRASH: No confirmation arrives, timeout occurs
    std::thread::sleep(Duration::from_millis(150));

    // Recovery: cleanup timeouts
    let recovered = pool.cleanup_timeouts(200);

    // All pending_inclusion should be recovered
    assert_eq!(
        recovered.len(),
        25,
        "Not all transactions recovered: {} of 25",
        recovered.len()
    );

    // Pool should be consistent
    assert_eq!(pool.pending_count(), 50);
    assert_eq!(pool.pending_inclusion_count(), 0);

    // All transactions should be selectable again
    let batch = pool.get_for_block(50, u64::MAX);
    assert_eq!(batch.len(), 50, "All txs should be selectable");

    println!("✅ Recovered from mid-proposal failure");
}

/// BRUTAL TEST: Partial confirmation handling
#[tokio::test]
async fn brutal_partial_confirmation() {
    let mut pool = TransactionPool::new(MempoolConfig {
        max_transactions: 100,
        ..MempoolConfig::default()
    });

    // Add transactions
    let mut hashes = Vec::new();
    for i in 0..20u8 {
        let tx = create_tx(i, 0, 1_000_000_000);
        hashes.push(tx.hash);
        pool.add(tx).unwrap();
    }

    // Propose all
    pool.propose(&hashes, 1, 0);
    assert_eq!(pool.pending_inclusion_count(), 20);

    // Confirm only HALF (simulates partial block inclusion)
    let confirmed_hashes: Vec<_> = hashes.iter().take(10).cloned().collect();
    let removed = pool.confirm(&confirmed_hashes);

    assert_eq!(removed.len(), 10, "Should remove confirmed txs");

    // Remaining should still be pending_inclusion
    assert_eq!(pool.pending_inclusion_count(), 10);

    // Rollback the unconfirmed
    let remaining_hashes: Vec<_> = hashes.iter().skip(10).cloned().collect();
    let rolled_back = pool.rollback(&remaining_hashes);

    assert_eq!(rolled_back.len(), 10, "Should rollback unconfirmed");
    assert_eq!(pool.pending_count(), 10, "Rolled back should be pending");
    assert_eq!(pool.pending_inclusion_count(), 0);

    println!("✅ Handled partial confirmation correctly");
}

/// BRUTAL TEST: Double-confirmation attack
#[tokio::test]
async fn brutal_double_confirmation() {
    let mut pool = TransactionPool::new(MempoolConfig::default());

    // Add a transaction
    let tx = create_tx(0xAA, 0, 1_000_000_000);
    let hash = tx.hash;
    pool.add(tx).unwrap();

    // Propose it
    pool.propose(&[hash], 1, 0);

    // First confirmation
    let first_remove = pool.confirm(&[hash]);
    assert_eq!(first_remove.len(), 1, "First confirmation should work");

    // Second confirmation (double-spend attempt)
    let second_remove = pool.confirm(&[hash]);
    assert_eq!(
        second_remove.len(),
        0,
        "Second confirmation should be no-op"
    );

    // Pool should be empty
    assert_eq!(pool.len(), 0);

    println!("✅ Double-confirmation attack prevented");
}

// ============================================================================
// CORRUPTION HANDLING TESTS
// ============================================================================

/// BRUTAL TEST: Handle corrupted transaction hash
#[test]
fn brutal_corrupted_hash_handling() {
    let mut pool = TransactionPool::new(MempoolConfig::default());

    // Add legitimate transactions
    for i in 0..10u8 {
        let tx = create_tx(i, 0, 1_000_000_000);
        pool.add(tx).unwrap();
    }

    // Try to query with corrupted/non-existent hash
    let corrupted_hash: [u8; 32] = [0xFF; 32];

    // These should not crash
    let get_result = pool.get(&corrupted_hash);
    assert!(get_result.is_none(), "Corrupted hash should return None");

    let contains_result = pool.contains(&corrupted_hash);
    assert!(!contains_result, "Corrupted hash should not exist");

    // Try to remove non-existent
    let remove_result = pool.confirm(&[corrupted_hash]);
    assert_eq!(remove_result.len(), 0, "Should not remove non-existent");

    // Try to propose non-existent
    let propose_result = pool.propose(&[corrupted_hash], 1, 0);
    assert_eq!(
        propose_result.proposed_count, 0,
        "Should not propose non-existent"
    );

    // Pool should be unaffected
    assert_eq!(pool.len(), 10, "Pool should still have 10 txs");

    println!("✅ Corrupted hash handling is safe");
}

/// BRUTAL TEST: Empty operation handling
#[test]
fn brutal_empty_operations() {
    let mut pool = TransactionPool::new(MempoolConfig::default());

    // Empty propose
    let propose_result = pool.propose(&[], 1, 0);
    assert_eq!(propose_result.proposed_count, 0);

    // Empty remove
    let remove_result = pool.confirm(&[]);
    assert_eq!(remove_result.len(), 0);

    // Empty rollback
    let non_existent_hash: [u8; 32] = [0xFF; 32];
    let rollback_result = pool.rollback(&[non_existent_hash]);
    assert_eq!(rollback_result.len(), 0);

    // Get from empty pool
    let batch = pool.get_for_block(100, u64::MAX);
    assert_eq!(batch.len(), 0);

    // Status of empty pool
    let status = pool.status(1000);
    assert_eq!(status.pending_count, 0);
    assert_eq!(status.memory_bytes, 0);

    println!("✅ Empty operations handled safely");
}

// ============================================================================
// GRACEFUL DEGRADATION TESTS
// ============================================================================

/// BRUTAL TEST: System under extreme load should degrade gracefully
#[tokio::test(flavor = "multi_thread", worker_threads = 8)]
async fn brutal_graceful_degradation() {
    let pool = Arc::new(Mutex::new(TransactionPool::new(MempoolConfig {
        max_transactions: 100, // Small limit
        ..MempoolConfig::default()
    })));

    let accepted = Arc::new(AtomicUsize::new(0));
    let rejected = Arc::new(AtomicUsize::new(0));
    let errors = Arc::new(AtomicUsize::new(0));

    let mut handles = vec![];

    // 50 threads, each sending 100 transactions = 5000 total
    // Pool can only hold 100, so most will be rejected
    for thread in 0..50u8 {
        let p = pool.clone();
        let acc = accepted.clone();
        let rej = rejected.clone();
        let err = errors.clone();

        handles.push(tokio::spawn(async move {
            for nonce in 0..100u64 {
                let tx = create_tx(thread, nonce, 1_000_000_000);

                let result = {
                    let mut guard = p.lock().await;
                    guard.add(tx)
                };

                match result {
                    Ok(_) => {
                        acc.fetch_add(1, Ordering::Relaxed);
                    }
                    Err(_) => {
                        rej.fetch_add(1, Ordering::Relaxed);
                    }
                }

                tokio::task::yield_now().await;
            }
        }));
    }

    for handle in handles {
        if handle.await.is_err() {
            errors.fetch_add(1, Ordering::Relaxed);
        }
    }

    let accepted_count = accepted.load(Ordering::Relaxed);
    let rejected_count = rejected.load(Ordering::Relaxed);
    let error_count = errors.load(Ordering::Relaxed);

    println!(
        "Graceful degradation: {} accepted, {} rejected, {} errors",
        accepted_count, rejected_count, error_count
    );

    // Should be no panics
    assert_eq!(error_count, 0, "Task panics detected");

    // Total should equal attempted
    assert_eq!(
        accepted_count + rejected_count,
        5000,
        "Some operations were lost"
    );

    // Pool should be at capacity
    let guard = pool.lock().await;
    assert!(guard.len() <= 100, "Pool exceeded capacity");

    println!("✅ System degraded gracefully under load");
}

/// BRUTAL TEST: Recovery from saturated state
#[tokio::test]
async fn brutal_recovery_from_saturation() {
    let mut pool = TransactionPool::new(MempoolConfig {
        max_transactions: 50,
        pending_inclusion_timeout_ms: 100,
        ..MempoolConfig::default()
    });

    // Saturate pool
    let mut hashes = Vec::new();
    for i in 0..50u8 {
        let tx = create_tx(i, 0, 1_000_000_000);
        hashes.push(tx.hash);
        pool.add(tx).unwrap();
    }

    assert_eq!(pool.len(), 50, "Pool should be saturated");

    // New transaction should fail
    let overflow_tx = create_tx(0xFF, 0, 1_000_000_000);
    assert!(pool.add(overflow_tx).is_err(), "Should reject when full");

    // Simulate block confirmation (removes transactions)
    let half: Vec<_> = hashes.iter().take(25).cloned().collect();
    pool.propose(&half, 1, 0);
    pool.confirm(&half);

    assert_eq!(pool.len(), 25, "Pool should have space");

    // Now new transactions should succeed
    let recovery_tx = create_tx(0xFE, 0, 1_000_000_000);
    assert!(
        pool.add(recovery_tx).is_ok(),
        "Should accept after space freed"
    );

    println!("✅ Recovered from saturated state");
}

// ============================================================================
// STATE RECOVERY TESTS
// ============================================================================

/// BRUTAL TEST: Pending inclusion recovery after crash
#[tokio::test]
async fn brutal_pending_inclusion_recovery() {
    let mut pool = TransactionPool::new(MempoolConfig {
        max_transactions: 100,
        pending_inclusion_timeout_ms: 50,
        ..MempoolConfig::default()
    });

    // Create and add transactions
    let mut hashes = Vec::new();
    for i in 0..30u8 {
        let tx = create_tx(i, 0, (30 - i) as u64 * 1_000_000_000); // Descending gas price
        hashes.push(tx.hash);
        pool.add(tx).unwrap();
    }

    // Propose all
    pool.propose(&hashes, 1, 0);
    assert_eq!(pool.pending_inclusion_count(), 30);
    assert_eq!(pool.pending_count(), 0);

    // "CRASH" - wait for timeout
    tokio::time::sleep(Duration::from_millis(100)).await;

    // Recovery
    let recovered = pool.cleanup_timeouts(200);

    // All should be recovered
    assert_eq!(recovered.len(), 30);
    assert_eq!(pool.pending_count(), 30);
    assert_eq!(pool.pending_inclusion_count(), 0);

    // Transactions should maintain their original ordering by gas price
    let batch = pool.get_for_block(30, u64::MAX);

    // First transaction should have highest gas price
    let first_gas = batch[0].gas_price;
    let last_gas = batch[29].gas_price;

    assert!(
        first_gas >= last_gas,
        "Priority order should be maintained after recovery"
    );

    println!("✅ Pending inclusion recovery successful with priority preserved");
}

/// BRUTAL TEST: Routing table recovery after peer failures
#[tokio::test]
async fn brutal_routing_recovery_peer_failures() {
    let local_id = NodeId::new([0u8; 32]);
    let config = KademliaConfig::default();
    let mut table = RoutingTable::new(local_id, config);
    let now = Timestamp::new(1000);

    // Add 50 peers
    let mut peer_ids = Vec::new();
    for i in 0..50u8 {
        let node_id = NodeId::new([i + 1; 32]); // +1 to avoid local_id
        let peer = PeerInfo::new(
            node_id,
            SocketAddr::new(IpAddr::v4(10, 0, 0, i + 1), 30303),
            now,
        );

        if table.stage_peer(peer, now).is_ok() {
            let _ = table.on_verification_result(&node_id, true, now);
            peer_ids.push(node_id);
        }
    }

    let initial_stats = table.stats(now);
    let initial_count = initial_stats.total_peers;

    // Simulate 50% of peers failing
    for id in peer_ids.iter().take(25) {
        // Mark as failed
        let _ = table.on_verification_result(id, false, Timestamp::new(2000));
    }

    let after_failure = table.stats(Timestamp::new(2000));

    // Some peers should be removed or marked
    println!(
        "Before failure: {} peers, After failure: {} peers",
        initial_count, after_failure.total_peers
    );

    // Add replacement peers
    for i in 100..120u8 {
        let node_id = NodeId::new([i; 32]);
        let peer = PeerInfo::new(
            node_id,
            SocketAddr::new(IpAddr::v4(10, 1, 0, i), 30303),
            Timestamp::new(3000),
        );

        let _ = table.stage_peer(peer, Timestamp::new(3000));
        let _ = table.on_verification_result(&node_id, true, Timestamp::new(3001));
    }

    let final_stats = table.stats(Timestamp::new(4000));

    println!("After recovery: {} peers", final_stats.total_peers);

    // Should have recovered
    assert!(
        final_stats.total_peers > after_failure.total_peers / 2,
        "Table should recover after peer failures"
    );

    println!("✅ Routing table recovered from peer failures");
}

// ============================================================================
// EDGE CASE FAILURE TESTS
// ============================================================================

/// BRUTAL TEST: Maximum capacity boundary
#[test]
fn brutal_max_capacity_boundary() {
    let config = MempoolConfig {
        max_transactions: 10,
        max_per_account: 5,
        ..MempoolConfig::default()
    };
    let mut pool = TransactionPool::new(config);

    // Fill exactly to capacity with different senders
    for i in 0..10u8 {
        let tx = create_tx(i, 0, 1_000_000_000);
        assert!(pool.add(tx).is_ok(), "Should accept tx {} at capacity", i);
    }

    assert_eq!(pool.len(), 10, "Should be exactly at capacity");

    // One more should fail
    let overflow = create_tx(0xFE, 0, 1_000_000_000);
    assert!(pool.add(overflow).is_err(), "Should reject at capacity");

    // Remove one
    let _status = pool.status(1000);
    let batch = pool.get_for_block(1, u64::MAX);
    let hash_to_remove = batch[0].hash;
    drop(batch); // Release borrow
    pool.propose(&[hash_to_remove], 1, 0);
    pool.confirm(&[hash_to_remove]);

    assert_eq!(pool.len(), 9, "Should have one less");

    // Now one more should succeed
    let new_tx = create_tx(0xFD, 0, 1_000_000_000);
    assert!(pool.add(new_tx).is_ok(), "Should accept after removal");

    println!("✅ Capacity boundary handling correct");
}

/// BRUTAL TEST: Per-account limit boundary
#[test]
fn brutal_per_account_limit_boundary() {
    let config = MempoolConfig {
        max_transactions: 100,
        max_per_account: 5,
        ..MempoolConfig::default()
    };
    let mut pool = TransactionPool::new(config);

    let sender = [0xAA; 20];

    // Fill to per-account limit
    for nonce in 0..5u64 {
        let tx = SignedTransaction {
            from: sender,
            to: Some([0xBB; 20]),
            value: U256::zero(),
            nonce,
            gas_price: U256::from(1_000_000_000u64),
            gas_limit: 21000,
            data: vec![],
            signature: [0u8; 64],
        };
        let mempool_tx = MempoolTransaction::new(tx, 1000);
        assert!(
            pool.add(mempool_tx).is_ok(),
            "Should accept nonce {}",
            nonce
        );
    }

    // One more from same account should fail
    let overflow = SignedTransaction {
        from: sender,
        to: Some([0xBB; 20]),
        value: U256::zero(),
        nonce: 5,
        gas_price: U256::from(1_000_000_000u64),
        gas_limit: 21000,
        data: vec![],
        signature: [0u8; 64],
    };
    let overflow_tx = MempoolTransaction::new(overflow, 1000);
    let result = pool.add(overflow_tx);

    assert!(result.is_err(), "Should reject 6th tx from same account");

    // Different account should still work
    let other = create_tx(0xBB, 0, 1_000_000_000);
    assert!(pool.add(other).is_ok(), "Different account should work");

    println!("✅ Per-account limit boundary handling correct");
}
